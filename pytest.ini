[tool:pytest]
# üß™ AI Portfolio Return Calculator - Professional pytest Configuration
# Comprehensive testing framework configuration for production-grade testing
# Last Updated: December 2024

# ==========================================
# üìÅ TEST DISCOVERY
# ==========================================
testpaths = 
    .
    tests

python_files = 
    test_*.py
    *_test.py
    tests.py

python_classes = 
    Test*
    *Tests

python_functions = 
    test_*

# ==========================================
# üîß BASIC CONFIGURATION
# ==========================================
minversion = 6.0
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --show-capture=no
    --durations=10
    --color=yes

# ==========================================
# üìä COVERAGE CONFIGURATION
# ==========================================
# Coverage reporting
addopts = 
    --cov=portfolio_return_calculator
    --cov=streamlit_portfolio_app
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-fail-under=85

# ==========================================
# üè∑Ô∏è TEST MARKERS
# ==========================================
markers =
    unit: Unit tests for individual components
    integration: Integration tests for complete workflows
    performance: Performance and benchmark tests
    slow: Slow running tests (mark with @pytest.mark.slow)
    fast: Fast running tests (mark with @pytest.mark.fast)
    smoke: Smoke tests for basic functionality
    regression: Regression tests for bug fixes
    api: API endpoint tests
    ui: User interface tests
    data: Data processing tests
    calculation: Mathematical calculation tests
    visualization: Chart and plot generation tests
    ai: AI recommendation system tests
    security: Security and validation tests
    benchmark: Performance benchmark tests
    network: Tests requiring network access
    database: Tests requiring database access
    external: Tests requiring external services

# ==========================================
# ‚ö†Ô∏è WARNING FILTERS
# ==========================================
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning:pandas.*
    ignore::DeprecationWarning:numpy.*
    ignore::PendingDeprecationWarning
    ignore::FutureWarning:plotly.*
    ignore::ResourceWarning

# ==========================================
# üéØ TEST EXECUTION
# ==========================================
# Timeout for individual tests (in seconds)
timeout = 300

# Fail on first failure (for debugging)
# Uncomment to enable: --maxfail=1

# Run tests in parallel (requires pytest-xdist)
# Uncomment to enable: -n auto

# ==========================================
# üìù LOGGING CONFIGURATION
# ==========================================
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d %(funcName)s(): %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# ==========================================
# üîß ADVANCED CONFIGURATION
# ==========================================
# Collect test statistics
collect_ignore = [
    "setup.py",
    "build",
    "dist",
    ".git",
    "__pycache__",
    "*.egg-info"
]

# Test discovery patterns
norecursedirs = 
    .git
    .tox
    dist
    build
    *.egg
    __pycache__
    .pytest_cache
    .venv
    venv
    env

# ==========================================
# üé® OUTPUT FORMATTING
# ==========================================
# Console output formatting
console_output_style = progress

# JUnit XML output (for CI/CD)
junit_family = xunit2
junit_logging = system-out
junit_log_passing_tests = false

# ==========================================
# üöÄ PERFORMANCE OPTIMIZATION
# ==========================================
# Cache test results
cache_dir = .pytest_cache

# Disable cacheprovider for clean runs
# Uncomment to disable: --cache-clear

# ==========================================
# üêõ DEBUGGING OPTIONS
# ==========================================
# Drop into debugger on failures (for development)
# Uncomment to enable: --pdb

# Drop into debugger on first failure
# Uncomment to enable: --pdbcls=IPython.terminal.debugger:Pdb

# ==========================================
# üìä PROFILING & BENCHMARKING
# ==========================================
# Enable profiling (requires pytest-profiling)
# Uncomment to enable: --profile

# Benchmark configuration (requires pytest-benchmark)
benchmark_only = false
benchmark_sort = mean
benchmark_warmup = true
benchmark_disable_gc = true

# ==========================================
# üåê ENVIRONMENT CONFIGURATION
# ==========================================
# Set environment variables for testing
env =
    TESTING = true
    STREAMLIT_ENV = test
    DISABLE_LOGGING = false
    CACHE_TYPE = simple

# ==========================================
# üìã EXAMPLE TEST COMMANDS
# ==========================================
# Run all tests:
#   pytest

# Run with coverage:
#   pytest --cov

# Run only unit tests:
#   pytest -m unit

# Run only fast tests:
#   pytest -m fast

# Run tests in parallel:
#   pytest -n auto

# Run with profiling:
#   pytest --profile

# Run specific test file:
#   pytest test_portfolio_calculator.py

# Run specific test:
#   pytest test_portfolio_calculator.py::TestPortfolioReturnCalculator::test_initialization

# Run tests and generate HTML coverage report:
#   pytest --cov --cov-report=html

# Run tests with JUnit XML output for CI:
#   pytest --junitxml=test-results.xml

# ==========================================
# üîÑ INTEGRATION WITH CI/CD
# ==========================================
# GitHub Actions configuration example:
# - name: Run tests
#   run: |
#     pytest --cov --cov-report=xml --junitxml=test-results.xml

# Jenkins configuration example:
# sh 'pytest --cov --cov-report=xml --junitxml=test-results.xml'

# GitLab CI configuration example:
# script:
#   - pytest --cov --cov-report=xml --junitxml=test-results.xml 